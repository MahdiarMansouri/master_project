{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-19T17:25:06.662172700Z",
     "start_time": "2024-02-19T17:25:06.607355700Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# ### preparing Data\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(f'your device is {device}')\n",
    "# \n",
    "# mean = np.array([0.485, 0.456, 0.406])\n",
    "# std = np.array([0.229, 0.224, 0.255])\n",
    "# \n",
    "# batch_size = 32\n",
    "# \n",
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         # transforms.Grayscale(),\n",
    "#         transforms.RandomResizedCrop((224, 224)),\n",
    "#         transforms.Normalize(mean, std)\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         # transforms.Grayscale(),\n",
    "#         transforms.RandomResizedCrop((224, 224)),\n",
    "#         transforms.Normalize(mean, std)\n",
    "#     ])\n",
    "# }\n",
    "# \n",
    "# data_path = 'D:\\Master Project\\model\\model-1\\data'\n",
    "# datasets = {x: ImageFolder(root=os.path.join(data_path, x), transform=data_transforms[x]) for x in ['train', 'val']}\n",
    "# print('datasets have been created')\n",
    "# \n",
    "# dataloaders = {x: DataLoader(dataset=datasets[x], batch_size=batch_size, num_workers=2, shuffle=False, drop_last=True)\n",
    "#                for x in ['train', 'val']}\n",
    "# print('dataloaders have been created')\n",
    "# \n",
    "# class_names = datasets['train'].classes\n",
    "# print(f'there are {len(class_names)} classes, and class names are {class_names}')\n",
    "# \n",
    "# from collections import Counter\n",
    "# \n",
    "# class_counts = Counter()\n",
    "# \n",
    "# for phase in ['train', 'val']:\n",
    "#     for _, label in dataloaders[phase]:\n",
    "#         class_counts.update(label.tolist())\n",
    "# \n",
    "# # show details\n",
    "# for label, count in class_counts.items():\n",
    "#     print(f'Class {label}: {count} instances')\n",
    "# \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T17:25:06.675129300Z",
     "start_time": "2024-02-19T17:25:06.633269100Z"
    }
   },
   "id": "cd0c7be8ff004fd5"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your device is cuda\n",
      "Datasets have been created.\n",
      "Dataloaders have been created.\n",
      "There are 2 classes, and class names are ['myxo', 'non-myxo']\n",
      "Dataset sizes: {'train': 620, 'val': 264}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 15656, 10260) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mEmpty\u001B[0m                                     Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1132\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\queues.py:114\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout):\n\u001B[1;32m--> 114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "\u001B[1;31mEmpty\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[76], line 105\u001B[0m\n\u001B[0;32m    102\u001B[0m class_counts \u001B[38;5;241m=\u001B[39m Counter()\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m phase \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m--> 105\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, label \u001B[38;5;129;01min\u001B[39;00m dataloaders[phase]:\n\u001B[0;32m    106\u001B[0m         class_counts\u001B[38;5;241m.\u001B[39mupdate(label\u001B[38;5;241m.\u001B[39mtolist())\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# show details\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1327\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1328\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1331\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1290\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[0;32m   1291\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[0;32m   1292\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1293\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m-> 1294\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1296\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1144\u001B[0m     pids_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(w\u001B[38;5;241m.\u001B[39mpid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[1;32m-> 1145\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpids_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) exited unexpectedly\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue\u001B[38;5;241m.\u001B[39mEmpty):\n\u001B[0;32m   1147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 15656, 10260) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Custom dataset class to handle oversampling\n",
    "class BalancedImageFolder(ImageFolder):\n",
    "    def __init__(self, root, transform=None, minority_class=0, augment_transforms=None):\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.minority_class = minority_class\n",
    "        self.augment_transforms = augment_transforms\n",
    "\n",
    "        # Identify the minority and majority classes and their counts\n",
    "        class_counts = self._get_class_counts()\n",
    "        self.max_count = max(class_counts.values())\n",
    "        self.indices = self._oversample_indices(class_counts)\n",
    "\n",
    "    def _get_class_counts(self):\n",
    "        class_counts = {}\n",
    "        for _, label in self.samples:\n",
    "            class_counts[label] = class_counts.get(label, 0) + 1\n",
    "        return class_counts\n",
    "\n",
    "    def _oversample_indices(self, class_counts):\n",
    "        # Oversample minority indices\n",
    "        minority_indices = [i for i, (_, label) in enumerate(self.samples) if label == self.minority_class]\n",
    "        required_samples = self.max_count - class_counts[self.minority_class]\n",
    "        oversampled_minority_indices = resample(minority_indices, replace=True, n_samples=required_samples, random_state=123)\n",
    "        return list(range(len(self.samples))) + oversampled_minority_indices\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        actual_index = self.indices[index]\n",
    "        path, target = self.samples[actual_index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if target == self.minority_class and self.augment_transforms is not None:\n",
    "            sample = self.augment_transforms(sample)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "# Device configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'your device is {device}')\n",
    "\n",
    "# Data normalization mean and std\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.255])\n",
    "\n",
    "# Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Additional augmentations for the minority class\n",
    "minority_augment_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "])\n",
    "\n",
    "# Standard data transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Path to your data\n",
    "data_path = 'D:\\\\Master Project\\\\model\\\\model-1\\\\data'\n",
    "\n",
    "# Creating datasets with BalancedImageFolder\n",
    "datasets = {\n",
    "    x: BalancedImageFolder(\n",
    "        root=os.path.join(data_path, x),\n",
    "        transform=data_transforms[x],\n",
    "        minority_class=0,  \n",
    "        augment_transforms=minority_augment_transforms if x == 'train' else None,\n",
    "    ) for x in ['train', 'val']\n",
    "}\n",
    "print('Datasets have been created.')\n",
    "\n",
    "# Creating dataloaders\n",
    "dataloaders = {\n",
    "    x: DataLoader(dataset=datasets[x], batch_size=batch_size, num_workers=2, shuffle=True if x == 'train' else False, drop_last=True)\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "print('Dataloaders have been created.')\n",
    "\n",
    "# Get class names\n",
    "class_names = datasets['train'].classes\n",
    "print(f'There are {len(class_names)} classes, and class names are {class_names}')\n",
    "\n",
    "# Count class instances\n",
    "class_counts = {x: len(datasets[x]) for x in ['train', 'val']}\n",
    "print(f'Dataset sizes: {class_counts}')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter()\n",
    "\n",
    "for phase in ['train', 'val']:\n",
    "    for _, label in dataloaders[phase]:\n",
    "        class_counts.update(label.tolist())\n",
    "\n",
    "# show details\n",
    "for label, count in class_counts.items():\n",
    "    print(f'Class {label}: {count} instances')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T17:26:48.790470600Z",
     "start_time": "2024-02-19T17:26:43.610790900Z"
    }
   },
   "id": "98d608428fb4fb7d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv4(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv5(x)))\n",
    "        x = x.view(-1, 512 * 7 * 7)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# model = SimpleCNN()\n",
    "# input_size = (3, 224, 224)\n",
    "# model = model.to(device)\n",
    "# summary(model, input_size)\n",
    "# print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T17:25:11.835819700Z",
     "start_time": "2024-02-19T17:25:11.823859700Z"
    }
   },
   "id": "9ac1b3360c0f32b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "last_layer = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    ")\n",
    "\n",
    "model.classifier = last_layer\n",
    "model.classifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T17:25:11.825853600Z"
    }
   },
   "id": "c095fc045ba2bddd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "\n",
    "\n",
    "# train function \n",
    "def train_model(model, criterion, optimizer, dataloaders, datasets, epoch_num=25):\n",
    "    acc_list = EasyDict({'train': [], 'val': []})\n",
    "    loss_list = EasyDict({'train': [], 'val': []})\n",
    "\n",
    "    # Copy the best model weights for loading at the End\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Iterating over epochs\n",
    "    for epoch in range(1, epoch_num + 1):\n",
    "        print(f'Epoch {epoch}/{epoch_num}:')\n",
    "\n",
    "        # Each epoch has two phase Train and Validation\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            # For calculating Loss and Accuracy at the end of epoch\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterating over batches and data for training and validation\n",
    "            for idx, batch in enumerate(dataloaders[phase], 0):\n",
    "                inputs, labels = batch\n",
    "\n",
    "                # Transfer data and labels to CUDA if is available\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward Pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "                    # Back Propagation and updating weights\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(predictions == labels.data)\n",
    "\n",
    "            # Calculating Accuracy and Loss per phase\n",
    "            epoch_loss = running_loss / len(datasets[phase])\n",
    "            epoch_accuracy = running_corrects.double() / len(datasets[phase])\n",
    "\n",
    "            # Show epoch details\n",
    "            print(f'{phase.capitalize()} Accuracy: {epoch_accuracy:.4f} / Loss: {epoch_loss:.4f}')\n",
    "\n",
    "            # Copy the model weights if its better\n",
    "            if phase == 'val' and epoch_accuracy > best_accuracy:\n",
    "                best_accuracy = epoch_accuracy\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('Best model weights updated!')\n",
    "\n",
    "            # Save Loss and accuracy\n",
    "            acc_list[phase].append(epoch_accuracy)\n",
    "            loss_list[phase].append(epoch_loss)\n",
    "        print()\n",
    "\n",
    "    print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "\n",
    "    # Loading best model weights \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, acc_list, loss_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T17:25:11.828843700Z"
    }
   },
   "id": "af8ddccf3dc2d4b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "model = model.to(device)\n",
    "# train model\n",
    "model, acc_lists, loss_lists = train_model(model, criterion, optimizer, dataloaders, datasets, epoch_num=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T17:25:11.830836500Z"
    }
   },
   "id": "c726d9e2b87f0f9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([a.cpu() for a in acc_lists.train], label='train')\n",
    "plt.plot([a.cpu() for a in acc_lists.val], label='val')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Percent')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T17:25:11.831833100Z"
    }
   },
   "id": "ae95ec69c97b6ef8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([a for a in loss_lists.train], label='train')\n",
    "plt.plot([a for a in loss_lists.val if a < 1], label='val')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Percent')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T17:25:11.832829600Z"
    }
   },
   "id": "91bd40ce7cca8561"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_model(model):\n",
    "    model.eval()\n",
    "    nrows, ncols = 4, 4\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                img = inputs.cpu().data[j]\n",
    "                img = img.numpy().transpose((1, 2, 0))\n",
    "                img = std * img + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "                axes[i][j].axis('off')\n",
    "                axes[i][j].set_title(\n",
    "                    f'predictions: {class_names[predictions[j]]}, label: {class_names[labels[j]]}'\n",
    "                )\n",
    "                axes[i][j].imshow(img)\n",
    "                if j == ncols - 1:\n",
    "                    break\n",
    "            if i == nrows - 1:\n",
    "                break\n",
    "\n",
    "\n",
    "visualize_model(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T17:25:11.833826500Z"
    }
   },
   "id": "676185da7a3dfdb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-19T17:25:11.834822800Z"
    }
   },
   "id": "fbbe7842ea3af627"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
