{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ViT Small Pretrained on DINOv2 with registers \n",
    "\n",
    "## Augmentation: TrivialAugmentWide to 60000 samples\n",
    "\n",
    "## Data: Corallo vs Myxo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1410a8d31948e1e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### import requirements"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c10a7389c7dee4cc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T10:58:38.258245900Z",
     "start_time": "2024-04-25T10:58:36.683240300Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms, autoaugment, InterpolationMode\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da703ffb580a457e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Original Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94a6895498d51d47"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your device is cuda\n",
      "datasets have been created\n",
      "dataloaders have been created\n",
      "there are 2 classes, and class names are ['Corallococcus', 'Myxococcus']\n",
      "Dataset sizes: {'train': 3735, 'val': 900}\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'your device is {device}')\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.255])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomResizedCrop((224, 224)),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomResizedCrop((224, 224)),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_path = 'D:\\Master Project\\model\\model-1\\Corallo-vs-Myxo2'\n",
    "datasets = {x: ImageFolder(root=os.path.join(data_path, x), transform=data_transforms[x]) for x in ['train', 'val']}\n",
    "print('datasets have been created')\n",
    "\n",
    "dataloaders = {x: DataLoader(dataset=datasets[x], batch_size=batch_size, num_workers=2, shuffle=False, drop_last=True)\n",
    "               for x in ['train', 'val']}\n",
    "print('dataloaders have been created')\n",
    "\n",
    "class_names = datasets['train'].classes\n",
    "print(f'there are {len(class_names)} classes, and class names are {class_names}')\n",
    "\n",
    "class_counts = {x: len(datasets[x]) for x in ['train', 'val']}\n",
    "print(f'Dataset sizes: {class_counts}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:14:46.652886200Z",
     "start_time": "2024-04-21T15:14:46.540881600Z"
    }
   },
   "id": "fb23dc65e3ffa848"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Counting Classes "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "548f942236e3ab5a"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 2916 instances\n",
      "Class 1: 1692 instances\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_counts = Counter()\n",
    "\n",
    "for phase in ['train', 'val']:\n",
    "    for _, label in dataloaders[phase]:\n",
    "        class_counts.update(label.tolist())\n",
    "\n",
    "# show details\n",
    "for label, count in class_counts.items():\n",
    "    print(f'Class {label}: {count} instances')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:15:05.735484700Z",
     "start_time": "2024-04-21T15:14:46.635887Z"
    }
   },
   "id": "5254fb4ff3ed2113"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining Augmentation Class "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b8e13b60b46a67c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CustomAugmentedDataset(Dataset):\n",
    "    def __init__(self, root_dir, num_samples_per_class, transform=None, num_magnitude_bins=30):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images.\n",
    "            num_samples_per_class (int): Desired number of samples per class after augmentation.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.dataset = ImageFolder(root=root_dir)\n",
    "        self.classes = self.dataset.classes\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.transform = transform\n",
    "        self.augment_transform = transforms.Compose([\n",
    "            autoaugment.TrivialAugmentWide(num_magnitude_bins=num_magnitude_bins,\n",
    "                                           interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((224, 224))\n",
    "        ])\n",
    "        self.class_samples = self._balance_classes()\n",
    "\n",
    "    def _balance_classes(self):\n",
    "        from collections import defaultdict\n",
    "        class_indices = defaultdict(list)\n",
    "\n",
    "        for idx, (_, class_id) in enumerate(self.dataset.samples):\n",
    "            class_indices[class_id].append(idx)\n",
    "\n",
    "        # Reduce or oversample class indices to match num_samples_per_class\n",
    "        balanced_indices = []\n",
    "        for indices in class_indices.values():\n",
    "            if len(indices) >= self.num_samples_per_class:\n",
    "                balanced_indices.extend(indices[:self.num_samples_per_class])\n",
    "            else:\n",
    "                # Oversample if there are fewer samples than desired\n",
    "                oversampled_indices = indices * (self.num_samples_per_class // len(indices)) + indices[\n",
    "                                                                                               :self.num_samples_per_class % len(\n",
    "                                                                                                   indices)]\n",
    "                balanced_indices.extend(oversampled_indices)\n",
    "\n",
    "        return balanced_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[self.class_samples[idx]]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = self.augment_transform(img)\n",
    "        return img, label\n",
    "\n",
    "    def classes(self):\n",
    "        return self.classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T10:58:45.973717300Z",
     "start_time": "2024-04-25T10:58:45.931716900Z"
    }
   },
   "id": "c356a006813a5b0e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating Augmented Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4b16905939cec57"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created.\n",
      "Dataloaders created.\n",
      "--------------------------------------------------\n",
      "there are 2 classes, and class names are ['Corallococcus', 'Myxococcus']\n",
      "--------------------------------------------------\n",
      "train dataset:  60000\n",
      "val dataset:  6000\n"
     ]
    }
   ],
   "source": [
    "# Define Parameters\n",
    "data_path = 'D:\\Master Project\\model\\model-1\\Corallo-vs-Myxo2'\n",
    "num_magnitude_bins = 100\n",
    "train_num_samples_per_class = 30000\n",
    "val_num_samples_per_class = 3000\n",
    "\n",
    "# Define any additional transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Flipping the image horizontally\n",
    "    transforms.RandomRotation(degrees=20),  # Rotate by -20 to +20 degrees\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Translation\n",
    "    transforms.ColorJitter(brightness=0.2),  # Adjusting Brightness\n",
    "    transforms.ColorJitter(contrast=0.2)  # Adjusting Contrast\n",
    "])\n",
    "\n",
    "\n",
    "# Creating datasets\n",
    "# datasets = {\n",
    "#     x: CustomAugmentedDataset(root_dir=os.path.join(data_path, x),   num_magnitude_bins=num_magnitude_bins, num_samples_per_class=num_samples_per_class if x == 'train' else 5000) \n",
    "#     for x in ['train', 'val']\n",
    "# }\n",
    "datasets = {\n",
    "    'train': CustomAugmentedDataset(root_dir=os.path.join(data_path, 'train'), num_magnitude_bins=num_magnitude_bins, transform=transforms,\n",
    "                                    num_samples_per_class=train_num_samples_per_class),\n",
    "    'val': CustomAugmentedDataset(root_dir=os.path.join(data_path, 'val'),\n",
    "                                  num_magnitude_bins=num_magnitude_bins,\n",
    "                                  num_samples_per_class=val_num_samples_per_class),\n",
    "}\n",
    "print('Datasets created.')\n",
    "\n",
    "# Creating dataloaders\n",
    "batch_size = 64\n",
    "dataloaders = {\n",
    "    x: DataLoader(dataset=datasets[x], batch_size=batch_size, num_workers=5, shuffle=True if x == 'train' else False,\n",
    "                  drop_last=True)\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "print('Dataloaders created.')\n",
    "print('-' * 50)\n",
    "\n",
    "# Show Classes\n",
    "class_names = datasets['train'].classes\n",
    "print(f'there are {len(class_names)} classes, and class names are {class_names}')\n",
    "print('-' * 50)\n",
    "\n",
    "# Show datasets length \n",
    "print('train dataset: ', len(datasets['train']))\n",
    "print('val dataset: ', len(datasets['val']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T11:02:17.994135300Z",
     "start_time": "2024-04-25T11:02:17.958134800Z"
    }
   },
   "id": "b20c11b136a70725"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Counting Classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2907536d36769fb6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# \n",
    "# class_counts = Counter()\n",
    "# \n",
    "# for phase in ['train', 'val']:\n",
    "#     for _, label in dataloaders[phase]:\n",
    "#         class_counts.update(label.tolist())\n",
    "# \n",
    "# # show details\n",
    "# for label, count in class_counts.items():\n",
    "#     print(f'Class {label}: {count} instances')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:15:05.791490600Z",
     "start_time": "2024-04-21T15:15:05.778491200Z"
    }
   },
   "id": "21a0f2144b8d4dda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Showing augmented data sample "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb4362cb281e0985"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx:  22279\n",
      "idx type:  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mahdiar\\AppData\\Local\\Temp\\ipykernel_2832\\2278788804.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print('idx: ', int(idx))\n",
      "C:\\Users\\Mahdiar\\AppData\\Local\\Temp\\ipykernel_2832\\2278788804.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  image, label = datasets['train'][int(idx)]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124midx: \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mint\u001B[39m(idx))\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124midx type: \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mtype\u001B[39m(idx))\n\u001B[1;32m----> 7\u001B[0m image, label \u001B[38;5;241m=\u001B[39m \u001B[43mdatasets\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage type: \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mtype\u001B[39m(image))\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel: \u001B[39m\u001B[38;5;124m'\u001B[39m, label)\n",
      "Cell \u001B[1;32mIn[3], line 48\u001B[0m, in \u001B[0;36mCustomAugmentedDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     46\u001B[0m img, label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_samples[idx]]\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 48\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     50\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maugment_transform(img)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx = np.random.randint(0, 60000, size=1)\n",
    "\n",
    "print('idx: ', int(idx))\n",
    "print('idx type: ', type(idx))\n",
    "image, label = datasets['train'][int(idx)]\n",
    "print('image type: ', type(image))\n",
    "print('label: ', label)\n",
    "print('class name label: ', class_names[label])\n",
    "\n",
    "# Convert torch tensor for plotting\n",
    "image = image.permute(1, 2, 0)\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T11:02:01.952321500Z",
     "start_time": "2024-04-25T11:02:01.916321100Z"
    }
   },
   "id": "f6fd339bc72cd98f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load ViT pretrained on DINOv2 with registers model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4146e0b7ca1cfad8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Mahdiar/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\Mahdiar/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\Mahdiar/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\Mahdiar/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "Using cache found in C:\\Users\\Mahdiar/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "Using cache found in C:\\Users\\Mahdiar/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "Using cache found in C:\\Users\\Mahdiar/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "# DINOv2\n",
    "dinov2_vits14_21M = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')\n",
    "dinov2_vitb14_86M = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')\n",
    "# dinov2_vitl14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')\n",
    "# dinov2_vitg14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14')\n",
    "\n",
    "# DINOv2 with registers\n",
    "dinov2_vits14_reg_21M = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14_reg')\n",
    "dinov2_vitb14_reg_86M = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14_reg')\n",
    "# dinov2_vitl14_reg = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14_reg')\n",
    "# dinov2_vitg14_reg = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14_reg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:15:09.325743900Z",
     "start_time": "2024-04-21T15:15:05.946490700Z"
    }
   },
   "id": "d7e8b394f43e584f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tune model classifier and trainable parameters "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67796172e50e4566"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DinoVisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x NestedTensorBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MemEffAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): LayerScale()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): LayerScale()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = dinov2_vits14_reg_21M\n",
    "# model = dinov2_vitb14_reg_86M\n",
    "# print(model)\n",
    "# Define classifier for Binary Classification task\n",
    "model.head = nn.Sequential(\n",
    "    nn.Linear(384, 2)\n",
    ")\n",
    "print(model)\n",
    "\n",
    "# Set about 30% of parameters trainable \n",
    "model_params = 0\n",
    "for idx, param in enumerate(model.parameters()):\n",
    "    param.requires_grad = False\n",
    "    model_params += 1\n",
    "    if idx == 120:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:15:09.342743700Z",
     "start_time": "2024-04-21T15:15:09.325743900Z"
    }
   },
   "id": "abcde227a150ca83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining Train function "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea8eff45af7cf71e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from easydict import EasyDict\n",
    "\n",
    "\n",
    "# train function \n",
    "def train_model(model, criterion, optimizer, dataloaders, datasets, epoch_num=25):\n",
    "    acc_list = EasyDict({'train': [], 'val': []})\n",
    "    loss_list = EasyDict({'train': [], 'val': []})\n",
    "\n",
    "    # Copy the best model weights for loading at the End\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Iterating over epochs\n",
    "    for epoch in range(1, epoch_num + 1):\n",
    "        print(f'Epoch {epoch}/{epoch_num}:')\n",
    "\n",
    "        # Each epoch has two phase Train and Validation\n",
    "        for phase in ['train', 'val']:\n",
    "            s0 = datetime.now()\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            # For calculating Loss and Accuracy at the end of epoch\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            # Iterating over batches and data for training and validation\n",
    "            for idx, batch in enumerate(dataloaders[phase], 0):\n",
    "                inputs, labels = batch\n",
    "\n",
    "                # Transfer data and labels to CUDA if is available\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward Pass\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "                    # Back Propagation and updating weights\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(predictions == labels.data)\n",
    "\n",
    "            # Calculating Accuracy and Loss per phase\n",
    "            epoch_loss = running_loss / len(datasets[phase])\n",
    "            epoch_accuracy = running_corrects / len(datasets[phase])\n",
    "\n",
    "            # Show epoch details\n",
    "            delta = datetime.now() - s0\n",
    "            print(f'{phase.capitalize()} Accuracy: {epoch_accuracy:.4f} | Loss: {epoch_loss:.4f} | time: {delta}')\n",
    "\n",
    "            # Copy the model weights if its better\n",
    "            if phase == 'val' and epoch_accuracy > best_accuracy:\n",
    "                best_accuracy = epoch_accuracy\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                print('Best model weights updated!')\n",
    "\n",
    "            # Save Loss and accuracy\n",
    "            acc_list[phase].append(epoch_accuracy)\n",
    "            loss_list[phase].append(epoch_loss)\n",
    "        print('-' * 50)\n",
    "\n",
    "    print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "\n",
    "    # Loading best model weights \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, acc_list, loss_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:15:09.388743400Z",
     "start_time": "2024-04-21T15:15:09.345743400Z"
    }
   },
   "id": "ca51a45e8fe06df4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train ViT-s DINOv2 with registers \n",
    "---------------\n",
    "## Hyperparameters:\n",
    "### optimizer: Adam\n",
    "### criterion: CrossEntropy\n",
    "### Learning Rate: 0.0003\n",
    "### batch size: 32\n",
    "### epoch: 50"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f92ba5a34d052b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your device is cuda\n",
      "\n",
      "DinoVisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x NestedTensorBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MemEffAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls1): LayerScale()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ls2): LayerScale()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "--------------------------------------------------\n",
      "Epoch 1/10:\n"
     ]
    }
   ],
   "source": [
    "# Defining hyperparameters\n",
    "criterion = CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'your device is {device}', end='\\n\\n')\n",
    "optimizer = Adam(model.parameters(), lr=0.0003)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "print('-' * 50)\n",
    "\n",
    "# train model\n",
    "model, acc_lists, loss_lists = train_model(model, criterion, optimizer, dataloaders, datasets, epoch_num=10)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-21T15:15:09.359743800Z"
    }
   },
   "id": "725f402be2ffac6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot Results "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69f987c83ba60f81"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([a.cpu() for a in acc_lists.train], label='train')\n",
    "plt.plot([a.cpu() for a in acc_lists.val], label='val')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Percent')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a1662086cdffb60c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([a for a in loss_lists.train], label='train loss')\n",
    "plt.plot([a for a in loss_lists.val], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Percent')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "90d57ed078c0e3c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([a.cpu() for a in acc_lists.train], label='train acc')\n",
    "plt.plot([a.cpu() for a in acc_lists.val], label='val acc')\n",
    "plt.plot([a for a in loss_lists.train], label='train loss')\n",
    "plt.plot([a for a in loss_lists.val], label='val loss')\n",
    "plt.title('result')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Percent')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "611bf71796f956ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save best model weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e827c1fc21b70f2d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model, '../models/model_5.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "95cadb4080c327e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize model predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63985af179cb400b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_model(model):\n",
    "    model.eval()\n",
    "    nrows, ncols = 4, 4\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                img = inputs.cpu().data[j]\n",
    "                img = img.numpy().transpose((1, 2, 0))\n",
    "                # img = std * img + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "                axes[i][j].axis('off')\n",
    "                axes[i][j].set_title(\n",
    "                    f'predictions: {class_names[predictions[j]]}, label: {class_names[labels[j]]}'\n",
    "                )\n",
    "                axes[i][j].imshow(img)\n",
    "                if j == ncols - 1:\n",
    "                    break\n",
    "            if i == nrows - 1:\n",
    "                break\n",
    "    plt.savefig('vis.jpg')\n",
    "\n",
    "\n",
    "model = torch.load('../models/model_5.pth')\n",
    "visualize_model(model)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "640df5d24d8c574e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "\n",
    "def visualize_model(model):\n",
    "    model.eval()\n",
    "    nrows, ncols = 4, 4\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 10))\n",
    "\n",
    "    # Determine how many batches are in the dataloader\n",
    "    num_batches = len(dataloaders['val'])\n",
    "    # Generate random batch indices\n",
    "    random_batches = np.random.choice(range(num_batches), size=nrows, replace=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch_idx in enumerate(random_batches):\n",
    "            # Retrieve the batch by the random index\n",
    "            inputs, labels = next(itertools.islice(dataloaders['val'], batch_idx, None))\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(ncols):\n",
    "                if j >= inputs.size()[0]:  # Check if the batch is smaller than ncols\n",
    "                    break\n",
    "\n",
    "                img = inputs.cpu().data[j]\n",
    "                img = img.numpy().transpose((1, 2, 0))\n",
    "                img = np.clip(img, 0, 1)  # Normalize the image for display\n",
    "                axes[i][j].axis('off')\n",
    "                axes[i][j].set_title(\n",
    "                    f'predictions: {class_names[predictions[j]]}, label: {class_names[labels[j]]}'\n",
    "                )\n",
    "                axes[i][j].imshow(img)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = torch.load('../models/model_5.pth')\n",
    "visualize_model(model)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "50909ebbb91295ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tune model2 classifier and trainable parameters "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68cdfa0c0831d0cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define model\n",
    "model2 = dinov2_vits14_reg_21M\n",
    "\n",
    "# Define classifier for Binary Classification task\n",
    "model2.head = nn.Sequential(\n",
    "    nn.Linear(384, 2)\n",
    ")\n",
    "\n",
    "# Set about 30% of parameters trainable \n",
    "model_params = 0\n",
    "for idx, param in enumerate(model2.parameters()):\n",
    "    param.requires_grad = False\n",
    "    model_params += 1\n",
    "    if idx == 125:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4e4fcd5629682bb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train ViT-s DINOv2 with registers \n",
    "---------------\n",
    "## Hyperparameters:\n",
    "### optimizer: Adam\n",
    "### criterion: CrossEntropy\n",
    "### Learning Rate: 0.00005\n",
    "### batch size: 32\n",
    "### epoch: 50"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e525edccf787b17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Defining Hyperparameters\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# \n",
    "# for phase in ['train', 'val']:    \n",
    "#     for inputs, labels in dataloaders[phase]:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "#     \n",
    "criterion = CrossEntropyLoss()\n",
    "print(f'your device is {device}', end='\\n\\n')\n",
    "optimizer = Adam(model2.parameters(), lr=0.0005)\n",
    "model2 = model2.to(device)\n",
    "print(model2)\n",
    "print('-' * 50)\n",
    "\n",
    "# train model\n",
    "model2, acc_lists2, loss_lists2 = train_model(model2, criterion, optimizer, dataloaders, datasets, epoch_num=50)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4f5a14a9f3c363f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d13bc46a7f508b8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([a.cpu() for a in acc_lists2.train], label='train')\n",
    "plt.plot([a.cpu() for a in acc_lists2.val], label='val')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Percent')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7fa56938df7d88df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([a for a in loss_lists2.train], label='train loss')\n",
    "plt.plot([a for a in loss_lists2.val], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Percent')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "953edc34415d7aa3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot([a.cpu() for a in acc_lists2.train], label='train acc')\n",
    "plt.plot([a.cpu() for a in acc_lists2.val], label='val acc')\n",
    "plt.plot([a for a in loss_lists2.train], label='train loss')\n",
    "plt.plot([a for a in loss_lists2.val], label='val loss')\n",
    "plt.title('result')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Percent')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f23aba7bc0c815e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize model predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "902be7f60a3c3c8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize_model(model):\n",
    "    model.eval()\n",
    "    nrows, ncols = 4, 4\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                img = inputs.cpu().data[j]\n",
    "                img = img.numpy().transpose((1, 2, 0))\n",
    "                # img = std * img + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "                axes[i][j].axis('off')\n",
    "                axes[i][j].set_title(\n",
    "                    f'predictions: {class_names[predictions[j]]}, label: {class_names[labels[j]]}'\n",
    "                )\n",
    "                axes[i][j].imshow(img)\n",
    "                if j == ncols - 1:\n",
    "                    break\n",
    "            if i == nrows - 1:\n",
    "                break\n",
    "    plt.savefig('vis.jpg')\n",
    "\n",
    "\n",
    "visualize_model(model2)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a5d5bf061e5894d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save best model weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc545b1b94b38a73"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model, 'models/model_5.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2ae7dc97ee490f61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_cm(model):\n",
    "    y_true, y_pred = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloaders['val']:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            outputs = (torch.max(torch.exp(outputs), 1)[1]).data.cpu().numpy()\n",
    "            y_pred.extend(outputs)\n",
    "\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(\n",
    "        cm / np.sum(cm, axis=1)[:, None],\n",
    "        index=[i for i in class_names],\n",
    "        columns=[i for i in class_names]\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(df_cm, annot=True, cbar=False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "model = torch.load('../models/model_4.pth')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "plot_cm(model)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ebc05e2eebffe697"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1a72bcfd1425e3f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
